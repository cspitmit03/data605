"time", "id", "ease", nframes = 300) %>%
mutate(year = round(time), country = .group) %>%
left_join(gapminder, by=c("country","year","continent")) %>%
rename(population = pop.x)
p2 <- ggplot(gapminder_tween,
aes(x=x, y=y, frame = .frame)) +
geom_point(aes(size=population, color=continent),alpha=0.8) +
xlab("GDP per capita") +
ylab("Life expectancy at birth") +
scale_x_log10(labels=comma)
gganimate(p2, filename="gapminder-tween.gif", title_frame = FALSE, interval = 0.05)
libary(ggplot2)
library(ggplot2)
library(gganimate)
devtools::install_github("dgrtwo/gganimate")
install.packages("devtools")
devtools::install_github("dgrtwo/gganimate")
gapminder_tween <- tween_elements(gapminder_edit,
"time", "id", "ease", nframes = 300) %>%
mutate(year = round(time), country = .group) %>%
left_join(gapminder, by=c("country","year","continent")) %>%
rename(population = pop.x)
p2 <- ggplot(gapminder_tween,
aes(x=x, y=y, frame = .frame)) +
geom_point(aes(size=population, color=continent),alpha=0.8) +
xlab("GDP per capita") +
ylab("Life expectancy at birth") +
scale_x_log10(labels=comma)
gganimate(p2, filename="gapminder-tween.gif", title_frame = FALSE, interval = 0.05)
library(gganimate)
gapminder_tween <- tween_elements(gapminder_edit,
"time", "id", "ease", nframes = 300) %>%
mutate(year = round(time), country = .group) %>%
left_join(gapminder, by=c("country","year","continent")) %>%
rename(population = pop.x)
p2 <- ggplot(gapminder_tween,
aes(x=x, y=y, frame = .frame)) +
geom_point(aes(size=population, color=continent),alpha=0.8) +
xlab("GDP per capita") +
ylab("Life expectancy at birth") +
scale_x_log10(labels=comma)
gganimate(p2, filename="gapminder-tween.gif", title_frame = FALSE, interval = 0.05)
ggplot(gapminder_tween,
aes(x=x, y=y, frame = .frame)) +
geom_point(aes(size=population, color=continent),alpha=0.8) +
xlab("GDP per capita") +
ylab("Life expectancy at birth") +
scale_x_log10(labels=comma)
head(gapminder_tween)
ggplot(gapminder_tween,
aes(x=x, y=y, frame = .frame)) +
geom_point(aes(size=population, color=continent),alpha=0.8) +
xlab("GDP per capita") +
ylab("Life expectancy at birth")
p2<-ggplot(gapminder_tween,
aes(x=x, y=y, frame = .frame)) +
geom_point(aes(size=population, color=continent),alpha=0.8) +
xlab("GDP per capita") +
ylab("Life expectancy at birth")
gganimate(p2, filename="gapminder-tween.gif", title_frame = FALSE, interval = 0.05)
install.packages("magick")
gganimate(p2, filename="gapminder-tween.gif", title_frame = FALSE, interval = 0.05)
gganimate(p2, filename="gapminder-tween.gif", title_frame = FALSE, interval = 0.05)
1/(4*100/3)
1/(4/100/3)
1/(4**3/100)
1/(4*3/100)
1/(5*3/100)
1/(25*3/100)
1/(81*3/100)
1/(400*3/100)
install.packages("networkD3")
# Library
library(networkD3)
library(tidyverse)
install.packages("tidyverse")
# Library
library(networkD3)
library(tidyverse)
# Usually what you have is a connection data frame: a list of flows with intensity for each flow
links=data.frame(source=c("group_A","group_A", "group_B", "group_C", "group_C", "group_E"), target=c("group_C","group_D", "group_E", "group_F", "group_G", "group_H"), value=c(2,3, 2, 3, 1, 3))
# From these flows we need to create a node data frame: it lists every entities involved in the flow
nodes=data.frame(name=c(as.character(links$source), as.character(links$target)) %>% unique())
links
nodes
links$IDsource=match(links$source, nodes$name)-1
links$IDtarget=match(links$target, nodes$name)-1
links
sankeyNetwork(Links = links, Nodes = nodes,
Source = "IDsource", Target = "IDtarget",
Value = "value", NodeID = "name",
sinksRight=FALSE)
devtools::install_github("r-dbi/odbc")
library(tidyverse)
library(gganimate)
sigmoid <- function(x_from, x_to, y_from, y_to, scale = 5, n = 100) {
x <- seq(-scale, scale, length = n)
y <- exp(x) / (exp(x) + 1)
tibble(x = (x + scale) / (scale * 2) * (x_to - x_from) + x_from,
y = y * (y_to - y_from) + y_from)
}
n_points <- 400
data <- tibble(from = rep(4, n_points),
to = sample(1:4, n_points, TRUE),
color = sample(c("A", "B"), n_points, TRUE))
sigmoid(0, 1, as.numeric(data[2, 1]), as.numeric(data[2, 2]),
n = 100, scale = 10) %>%
ggplot(aes(x, y)) +
geom_point()
p <- sigmoid(0, 1, as.numeric(data[2, 1]), as.numeric(data[2, 2]),
n = 100, scale = 10) %>%
mutate(time = row_number()) %>%
ggplot(aes(x, y, frame = time)) +
geom_point()
gganimate(p)
10/ (sqrt(364)*.25^2)
sqrt(365*.25)
library(ggplot2)
library(dplyr)
df = arrange(cars, speed)
ggplot(data=cars_speed_df, aes(df$speed)) +
geom_histogram(aes(fill = ..count..)) +
scale_fill_gradient("Frequency", low = "blue", high = "red") +
labs(title = "Speed Counts") +
labs(x = "Speed") +
labs(y = "Count")
summary(model)
model = lm (df$dist ~ df$speed, data = df)
modelsum = summary(model)
print(modelsum)
model$coefficients[2]
model$coefficients[1]
summary(model)
knitr::opts_chunk$set(echo = TRUE)
library(e1071)
library(dplyr)
train = read.csv("train.csv")
head(summary(train))
summary(train$BsmtFinSF1)
summary(train$BsmtFinSF2)
train$BsmtFinSF12 = train$BsmtFinSF1+train$BsmtFinSF2
#fill NAs with 0.
train[is.na(train)] <- 0
train = read.csv("train.csv")
head(summary(train))
#fill NAs with 0.
train[is.na(train)] <- 0
summary(train$BsmtFinSF1)
summary(train$BsmtFinSF2)
train$BsmtFinSF12 = train$BsmtFinSF1+train$BsmtFinSF2
#function to get mode of a variable.
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
#test for skewneess
summary(train$BsmtFinSF12)[4]>summary(train$BsmtFinSF12)[3]
summary(train$BsmtFinSF12)[3]>getmode(train$BsmtFinSF12)
skewness(train$BsmtFinSF12)
#visual of skewness
par(mfrow=c(1,2))
hist(train$BsmtFinSF12, main ='Histogram of Usable \n Basement Area')
qqnorm(train$BsmtFinSF12, main ='QQ Plot of Usable \n Basement Area')
qqline(train$BsmtFinSF12)
xq1 <- quantile(train$BsmtFinSF12, 0.25)
yq2 <- quantile(train$SalePrice, 0.5)
rowcount <- dim(train)[1]
upperxq1yq2 <- filter(train, train$SalePrice > yq2 & train$BsmtFinSF12 > xq1) %>% count()
upperyq2 <- filter(train, train$SalePrice > yq2) %>% count()
(upperxq1yq2/rowcount) / (upperyq2/rowcount)
#insert into matrix table
d22<- filter(train, train$SalePrice > yq2 & train$BsmtFinSF12 > xq1) %>% count()
upperxq1yq2 <- filter(train, train$SalePrice > yq2 & train$BsmtFinSF12 > xq1) %>% count()
upperyq2 <- filter(train, train$SalePrice > yq2) %>% count()
(upperxq1yq2/rowcount) * (upperyq2/rowcount)
upperyq2xq1 <- filter(train, train$SalePrice > yq2 & train$BsmtFinSF12 < xq1) %>% count()
upperyq2 <- filter(train, train$SalePrice > yq2) %>% count()
(upperyq2xq1/rowcount)/(upperyq2/rowcount)
#Insert into matrix table
d21<- filter(train, train$SalePrice > yq2 & train$BsmtFinSF12 < xq1) %>% count()
#Insert into matrix table.  Fill in other items including row and column sums.
d23 <- filter(train, train$SalePrice > yq2) %>% count()
d13 <- dim(train)[1]-d23
d32 <- filter(train, train$BsmtFinSF12 > xq1) %>% count()
d31 <- dim(train)[1]-d32
d11 <- d31-d21
d12 <- d32-d22
d33 <- dim(train)[1]
#prepare table
tab <- matrix(c(d11,d21,d31,d12,d22,d32,d13,d23,d33), 3, 3, byrow = T)
print(tab)
PA <- d32/d33
PB <- d23/d33
PA*PB
chimat<-rbind(c(467,0),c(479,514))
chisq.test(chimat,correct=TRUE)
library("dplyr")
library(purrr)
library(tidyr)
library(ggplot2)
library(corrplot)
ntrain<-select_if(train, is.numeric)
ntrain %>%
keep(is.numeric) %>%                     # Keep only numeric columns
gather() %>%                             # Convert to key-value pairs
ggplot(aes(value)) +                     # Plot the values
facet_wrap(~ key, scales = "free") +   # In separate panels
geom_bar()                         # as density
ntrain %>%
keep(is.numeric) %>%                     # Keep only numeric columns
gather() %>%                             # Convert to key-value pairs
ggplot(aes(value)) +                     # Plot the values
facet_wrap(~ key, scales = "free") +   # In separate panels
geom_density()                         # as density
ggplot(train, aes(x=d,y=SalePrice)) + geom_point() + ggtitle("Finished Basement SF vs Sale Price") + xlab("Finished Basement (BsmtFinSF1 + BsmtFinSF2)")
ntrain<-select_if(train, is.numeric)
ntrain %>%
keep(is.numeric) %>%                     # Keep only numeric columns
gather() %>%                             # Convert to key-value pairs
ggplot(aes(value)) +                     # Plot the values
facet_wrap(~ key, scales = "free") +   # In separate panels
geom_bar()                         # as density
library("dplyr")
library(purrr)
library(tidyr)
library(ggplot2)
library(corrplot)
ntrain<-select_if(train, is.numeric)
ntrain %>%
keep(is.numeric) %>%                     # Keep only numeric columns
gather() %>%                             # Convert to key-value pairs
ggplot(aes(value)) +                     # Plot the values
facet_wrap(~ key, scales = "free") +   # In separate panels
geom_bar()                         # as density
ntrain %>%
keep(is.numeric) %>%                     # Keep only numeric columns
gather() %>%                             # Convert to key-value pairs
ggplot(aes(value)) +                     # Plot the values
facet_wrap(~ key, scales = "free") +   # In separate panels
geom_density()                         # as density
ggplot(train, aes(x=BsmtFinSF12,y=SalePrice)) + geom_point() + ggtitle("Finished Basement SF vs Sale Price") + xlab("Finished Basement (BsmtFinSF1 + BsmtFinSF2)")
subset <- select(train, TotalBsmtSF, TotRmsAbvGrd, LotArea, SalePrice)
subcor <- cor(subset)
corrplot(subcor, method="square")
ggplot(train, aes(x=BsmtFinSF12,y=SalePrice)) + geom_point() + ggtitle("Finished Basement SF vs Sale Price") + xlab("Finished Basement (BsmtFinSF1 + BsmtFinSF2)")
subset <- select(train, TotalBsmtSF, TotRmsAbvGrd, LotArea, SalePrice)
subcor <- cor(subset)
corrplot(subcor, method="square")
subset <- select(train, TotalBsmtSF, TotRmsAbvGrd, LotArea, SalePrice)
subcor <- cor(subset)
par(mfrow=c(1,2))
ggplot(train, aes(x=BsmtFinSF12,y=SalePrice)) + geom_point() + ggtitle("Finished Basement SF vs Sale Price") + xlab("Finished Basement (BsmtFinSF1 + BsmtFinSF2)")
corrplot(subcor, method="square")
par(mfrow=c(1,2))
corrplot(subcor, method="square")
ggplot(train, aes(x=BsmtFinSF12,y=SalePrice)) + geom_point() + ggtitle("Finished Basement SF vs Sale Price") + xlab("Finished Basement (BsmtFinSF1 + BsmtFinSF2)")
t.test(train$TotalBsmtSF, train$SalePrice)
cor.test(train$TotalBsmtSF, train$SalePrice, method = "pearson" , conf.level = 0.99)
cor.test(train$TotalBsmtSF, train$SalePrice, method = "pearson" , conf.level = 0.99)
library(MASS)
min(train$BsmtFinSF12)
train$BsmtFinSF122 <- train$BsmtFinSF12 + 1/10000
min(train$BsmtFinSF122)
#fit an exp dist
fitexpd <- fitdistr(train$BsmtFinSF122, "exponential")
lam <- fitexpd$estimate
print(lam)
s <- rexp(1000, lam)
#histogram of old and new
par(mfrow=c(1,2))
hist(train$BsmtFinSF12, main="Original Data from Train", xlab="TotBsmtFin (1 and 2)")
hist(s, main="Sample Data")
summary(model2)
#fit a linear regression model
newdatacor = cor(trainsub)
# Split data in reg and train
#using ntrain from the 2nd question
n <- nrow(ntrain) #1460 rows of data
shuffle_ntrain <- ntrain[sample(n), ]
train_indices <- 1:round(0.7 * n)
trainsub <- shuffle_ntrain[train_indices, ]
test_indices <- (round(0.7 * n) + 1):n
testsub <- shuffle_ntrain[test_indices, ]
testsub[is.na(testsub)] <- 0
ntrain[is.na(ntrain)] <- 0
#fit a linear regression model
newdatacor = cor(trainsub)
corrplot(newdatacor)
model <- lm(SalePrice ~ ., data=trainsub)
summary(model)
plot(model$residuals ~ model$fitted.values)
#extract variables that are significant and rerun model
sigvars <- data.frame(summary(model)$coef[summary(model)$coef[,4] <= .05, 4])
sigvars <- add_rownames(sigvars, "vars")
colist<-dplyr::pull(sigvars, vars)
idx <- match(colist, names(trainsub))
trainsub2 <- cbind(trainsub[,idx], trainsub['SalePrice'])
model2<-lm(SalePrice ~ ., data=trainsub2)
summary(model2)
library(e1071)
library(dplyr)
setwd("~/Documents/GitHub/data605/Final")
train = read.csv("train.csv")
head(summary(train))
#fill NAs with 0.
train[is.na(train)] <- 0
summary(train$BsmtFinSF1)
summary(train$BsmtFinSF2)
train$BsmtFinSF12 = train$BsmtFinSF1+train$BsmtFinSF2
type(train)
describe(train)
desc(train)
train[grepl("^SF", train)]
colnames(train)[grepl("^SF", colnames(train))]
train %>%
select(contains("SF"))
train %>%
select(contains("SF")) %>% rowSums(na.rm=TRUE) -> train$AllSF
summary(train)
train$SFlotRatio <- train$AllSF/train$LotArea
train$PriceperSF <- train$AllSF/train$SalePrice
#function to get mode of a variable.
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
#test for skewneess
summary(train$BsmtFinSF12)[4]>summary(train$BsmtFinSF12)[3]
summary(train$BsmtFinSF12)[3]>getmode(train$BsmtFinSF12)
skewness(train$BsmtFinSF12)
#visual of skewness
par(mfrow=c(1,2))
hist(train$BsmtFinSF12, main ='Histogram of Usable \n Basement Area')
qqnorm(train$BsmtFinSF12, main ='QQ Plot of Usable \n Basement Area')
qqline(train$BsmtFinSF12)
xq1 <- quantile(train$BsmtFinSF12, 0.25)
yq2 <- quantile(train$SalePrice, 0.5)
rowcount <- dim(train)[1]
upperxq1yq2 <- filter(train, train$SalePrice > yq2 & train$BsmtFinSF12 > xq1) %>% count()
upperyq2 <- filter(train, train$SalePrice > yq2) %>% count()
(upperxq1yq2/rowcount) / (upperyq2/rowcount)
#insert into matrix table
d22<- filter(train, train$SalePrice > yq2 & train$BsmtFinSF12 > xq1) %>% count()
upperxq1yq2 <- filter(train, train$SalePrice > yq2 & train$BsmtFinSF12 > xq1) %>% count()
upperyq2 <- filter(train, train$SalePrice > yq2) %>% count()
(upperxq1yq2/rowcount) * (upperyq2/rowcount)
upperyq2xq1 <- filter(train, train$SalePrice > yq2 & train$BsmtFinSF12 < xq1) %>% count()
upperyq2 <- filter(train, train$SalePrice > yq2) %>% count()
(upperyq2xq1/rowcount)/(upperyq2/rowcount)
#Insert into matrix table
d21<- filter(train, train$SalePrice > yq2 & train$BsmtFinSF12 < xq1) %>% count()
#Insert into matrix table.  Fill in other items including row and column sums.
d23 <- filter(train, train$SalePrice > yq2) %>% count()
d13 <- dim(train)[1]-d23
d32 <- filter(train, train$BsmtFinSF12 > xq1) %>% count()
d31 <- dim(train)[1]-d32
d11 <- d31-d21
d12 <- d32-d22
d33 <- dim(train)[1]
#prepare table
tab <- matrix(c(d11,d21,d31,d12,d22,d32,d13,d23,d33), 3, 3, byrow = T)
print(tab)
PA <- d32/d33
PB <- d23/d33
PA*PB
chimat<-rbind(c(467,0),c(479,514))
chisq.test(chimat,correct=TRUE)
library("dplyr")
library(purrr)
library(tidyr)
library(ggplot2)
library(corrplot)
ntrain<-select_if(train, is.numeric)
ntrain %>%
keep(is.numeric) %>%                     # Keep only numeric columns
gather() %>%                             # Convert to key-value pairs
ggplot(aes(value)) +                     # Plot the values
facet_wrap(~ key, scales = "free") +   # In separate panels
geom_bar()                         # as density
ntrain %>%
keep(is.numeric) %>%                     # Keep only numeric columns
gather() %>%                             # Convert to key-value pairs
ggplot(aes(value)) +                     # Plot the values
facet_wrap(~ key, scales = "free") +   # In separate panels
geom_density()                         # as density
subset <- select(train, TotalBsmtSF, TotRmsAbvGrd, LotArea, SalePrice)
subcor <- cor(subset)
par(mfrow=c(1,2))
ggplot(train, aes(x=BsmtFinSF12,y=SalePrice)) + geom_point() + ggtitle("Finished Basement SF vs Sale Price") + xlab("Finished Basement (BsmtFinSF1 + BsmtFinSF2)")
corrplot(subcor, method="square")
t.test(train$TotalBsmtSF, train$SalePrice)
cor.test(train$TotalBsmtSF, train$SalePrice, method = "pearson" , conf.level = 0.99)
chisq.test(train$TotalBsmtSF, train$SalePrice, correct=FALSE)
cor.test(train$TotalBsmtSF, train$SalePrice, method = "pearson" , conf.level = 0.92)
cor.test(train$TotalBsmtSF, train$SalePrice, method = "pearson" , conf.level = 0.92)
cor.test(train$TotRmsAbvGrd, train$SalePrice, method = "pearson" , conf.level = 0.92)
cor.test(train$LotArea, train$SalePrice, method = "pearson" , conf.level = 0.92)
1-(1-0.92)^3
1-0.92
^3
0.08^3
cor.test(train$TotalBsmtSF, train$SalePrice, method = "pearson" , conf.level = 0.9733)
cor.test(train$TotRmsAbvGrd, train$SalePrice, method = "pearson" , conf.level = 0.9733)
cor.test(train$LotArea, train$SalePrice, method = "pearson" , conf.level = 0.9733)
print(subcor)
inv<-solve(subcor)
print(inv)
round(subcor %*% inv)
round(inv %*% subcor)
library(Matrix)
lum <- lu(inv)
elu <- expand(lum)
elu$L
elu$U
round(elu$L,3)
library(Matrix)
lum <- lu(inv)
elu <- expand(lum)
round(elu$L,3)
round(elu$U,3)
library(MASS)
min(train$BsmtFinSF12)
train$BsmtFinSF122 <- train$BsmtFinSF12 + 1/10000
min(train$BsmtFinSF122)
#fit an exp dist
fitexpd <- fitdistr(train$BsmtFinSF122, "exponential")
lam <- fitexpd$estimate
print(lam)
s <- rexp(1000, lam)
#histogram of old and new
par(mfrow=c(1,2))
hist(train$BsmtFinSF12, main="Kaggle Data", xlab="TotBsmtFin (1 and 2)")
hist(s, main="Sampled Data")
# Obtain CDF for 5% and 95% for the sample data.
cdf_5 <- log(1 - .05)/-lam
cdf_95 <- log(1 - .95)/-lam
# obtain normality 5% and 95%
#this is done using quantiles which assume IID
quantile(train$BsmtFinSF12, 0.05)
quantile(train$BsmtFinSF12, 0.95)
#Generate Confidence Interval
#Use RMISC to calculate Confidence Interval
library(Rmisc)
CI(train$BsmtFinSF12, 0.95)
print(cdf_5)
print(cdf_95)
n <- nrow(ntrain) #1460 rows of data
shuffle_ntrain <- ntrain[sample(n), ]
train_indices <- 1:round(0.7 * n)
trainsub <- shuffle_ntrain[train_indices, ]
test_indices <- (round(0.7 * n) + 1):n
testsub <- shuffle_ntrain[test_indices, ]
testsub[is.na(testsub)] <- 0
ntrain[is.na(ntrain)] <- 0
#fit a linear regression model
newdatacor = cor(trainsub)
corrplot(newdatacor)
model <- lm(SalePrice ~ ., data=trainsub)
summary(model)
plot(model$residuals ~ model$fitted.values)
sigvars <- data.frame(summary(model)$coef[summary(model)$coef[,4] <= .05, 4])
sigvars <- add_rownames(sigvars, "vars")
colist<-dplyr::pull(sigvars, vars)
idx <- match(colist, names(trainsub))
trainsub2 <- cbind(trainsub[,idx], trainsub['SalePrice'])
model2<-lm(SalePrice ~ ., data=trainsub2)
summary(model2)
par(mfrow=c(1,2))
plot(model2$residuals ~ model2$fitted.values, main="New Reduced Var Model")
abline(h = 0)
plot(model$residuals ~ model$fitted.values, main="Orignal Model All Vars")
abline(h = 0)
summary(model)
summary(model2)
#import test data for submission
test = read.csv("test.csv")
#select only numeric columns
test <- select_if(test, is.numeric)
test[is.na(test)] <- 0
pred2<-predict(model2,test)
#import test data for submission
test = read.csv("test.csv")
#select only numeric columns
test <- select_if(test, is.numeric)
#generate new variables for model prediction
test %>% select(contains("SF")) %>% rowSums(na.rm=TRUE) -> test$AllSF
#import test data for submission
test = read.csv("test.csv")
#generate new variables for model prediction
test %>% select(contains("SF")) %>% rowSums(na.rm=TRUE) -> test$AllSF
test %>% select(contains("SF"))
test = read.csv("test.csv")
head(test)
test %>% select(contains("SF"))
library(e1071)
library(dplyr)
train = read.csv("train.csv")
head(summary(train))
#fill NAs with 0.
train[is.na(train)] <- 0
summary(train$BsmtFinSF1)
summary(train$BsmtFinSF2)
train$BsmtFinSF12 = train$BsmtFinSF1+train$BsmtFinSF2
train %>% select(contains("SF")) %>% rowSums(na.rm=TRUE) -> train$AllSF
train = read.csv("train.csv")
head(summary(train))
#fill NAs with 0.
train[is.na(train)] <- 0
summary(train$BsmtFinSF1)
summary(train$BsmtFinSF2)
train$BsmtFinSF12 = train$BsmtFinSF1+train$BsmtFinSF2
train %>% select(contains("SF")) %>% rowSums(na.rm=TRUE) -> train$AllSF
